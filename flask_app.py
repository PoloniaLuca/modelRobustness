import os
import subprocess
import logging
from pandas.errors import EmptyDataError
from pathlib import Path

## Development server requires we first copy all common libraries
if __name__ == "__main__":
    # subprocess.check_output('cp -nr ../../common/ .')
    f_path = Path(__file__)
    # source = os.path.join(f_path.parent.parent.parent, 'common/')
    # dest = str(f_path.parent) + '/'

    # output =subprocess.check_output(['rsync', '-a', '-v', source, dest])
    # print(output)

from utils.constants import constants

from flask import Flask, app, render_template, request, flash, g

# from numpy.lib.function_base import append
import pandas as pd
import numpy as np
from step_one import plot_step_one
from step_two import step_two

import matplotlib.pyplot as plt
import scipy.stats as stats
from werkzeug.utils import secure_filename
from compute import compute

path = os.getcwd()
UPLOAD_FOLDER = os.path.join(path, 'uploads')
ALLOWED_FILES = {'csv'}
TEST_FOLDER = os.path.join(path, 'static/testfiles/plt2/datasets')

app = Flask(__name__)


if not os.path.isdir(UPLOAD_FOLDER):
    os.mkdir(UPLOAD_FOLDER)

app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config["ALLOWED_FILES"] = ALLOWED_FILES
app.config["SECRET_KEY"] = 'f13783376341d2dddfaef175'
app.config['TEST_FOLDER'] = TEST_FOLDER

class Options:
    def __init__(self):
        eci_calibration = request.form.get('eci_calibration', request.args.get('eci_calibration', "off"))
        self.calibration_metric = 'brier' if eci_calibration == 'on' else 'eci'

        balanced_accuracy = request.form.get('balanced_accuracy', request.args.get('balanced_accuracy', "off"))
        self.discrimination_metric = 'bas' if balanced_accuracy == 'on' else 'auc'

        net_benefit = request.form.get('net_benefit', request.args.get('net_benefit', "off"))
        self.utility_metric = 'snb' if net_benefit == 'on' else 'wu'

def allowed_file(filename):
    return '.' in filename and \
        filename.rsplit('.', 1)[1].lower() in ALLOWED_FILES

@app.context_processor
def inject_constants():
    return dict(constants=constants)

@app.before_request
def before_request_callback():
    rawValue = request.args.get('tool') or request.form.get('tool');

    if (rawValue in ['pills-plt1','pills-plt2']):
        g.tool = rawValue
    else:
        g.tool = None

    g.options = Options()

@app.route('/plt1', methods=['POST', 'GET'])
@app.route('/plt2', methods=['POST', 'GET'])
@app.route("/", methods=['POST', 'GET'])
def choose_form(test1=False, test2 = False):

    if request.method == 'POST' or (test1 is True or test2 is True):

        options = g.options

        if request.form.get('submit', False) == 'submit_plt1':
            input = request.files['inputs']
            # print(app.config)
            # print(input)
            if input.filename == '':
                flash("input file is necessary!", category='warning')
                return render_template('home.html')

            if  not allowed_file(input.filename):
                flash("input file need .csv extension!", category='danger')
                return render_template('home.html')
            else:
                try:
                    data = pd.read_csv(input, sep=',').squeeze("columns")

                    sim = data['similarities'].to_numpy()
                    metrics = data['metrics'].to_numpy()

                    if sim.size != metrics.size:
                        flash("Similarities and metrics must have the same number of elements.", category='danger')
                        return render_template('home.html')

                    if np.isnan(np.sum(sim)) or np.isnan(np.sum(metrics)):
                        flash("Similarities and metrics must not have any missing values.", category='danger')
                        return render_template('home.html')

                    try:
                        img_step1 = plot_step_one(sim, metrics, scatter=True)
                    except ValueError as e:
                        if str(e) == 'x and y must have length at least 2.':
                            flash("The metrics file must contain similarities and metrics for at least two datasets generated by the repeated hold-out procedure.",category="danger")
                            return render_template("home.html")
                        else:
                            raise e

                except Exception as e:
                    logging.exception(e)
                    flash("One or more errors were encountered: please check your data, or contact us if the issue persists.",category="danger")
                    return render_template("home.html")


            return render_template('results_plt1.html', img_url = img_step1)

        if request.form.get('submit', False) == 'submit_plt2':

            sims_file = request.files['sims']
            datasets = request.files.getlist('datasets[]')
            offsets_auc = request.files['offsets_auc']
            offsets_nb = request.files['offsets_nb']
            offsets_brier = request.files['offsets_brier']

            if (sims_file.filename == ''):
                flash("Files marked with * are required, please insert all mandatory files.", category='danger')
                return render_template('home.html')

            if (not allowed_file(sims_file.filename)):
                flash("Mandatory files need .csv extension.", category='danger')
                return render_template('home.html')

            if ((offsets_auc.filename != '' and not allowed_file(offsets_auc.filename)) or (offsets_nb.filename != '' and not allowed_file(offsets_nb.filename))
                or (offsets_brier.filename != '' and not allowed_file(offsets_brier.filename))):
                flash("If inserted, offsets files need .csv extension.",category='danger')
                return render_template('home.html')

            try:
                try:
                    sims = pd.read_csv(sims_file, sep=',', usecols=['similarities'],header=0).squeeze("columns").to_numpy()
                except (ValueError):
                    sims_file.stream.seek(0)
                    sims = pd.read_csv(sims_file, sep=',', usecols=[0],header=None).squeeze("columns").to_numpy()


                # inizializzazione array per passagio dati a compute
                labels = np.array([])
                texts = np.array([])
                aucs = np.array([])
                nbs = np.array([])
                briers = np.array([])
                instances = np.array([])
                samples_auc = np.array([])
                samples_nb = np.array([])
                samples_brier = np.array([])
                var_auc = np.array([])
                var_nb = np.array([])
                var_brier = np.array([])

                if offsets_auc.filename != '':
                    offsets_auc = pd.read_csv(offsets_auc, sep=',',header=0).squeeze("columns")
                    offsets_x_auc = offsets_auc['offset_x'].fillna(0.1).to_numpy()
                    offsets_y_auc = offsets_auc['offset_y'].fillna(0.1).to_numpy()
                else:
                    offsets_x_auc = default_offsets(sims)
                    offsets_y_auc = default_offsets(sims)

                if offsets_nb.filename != '':
                    offsets_nb = pd.read_csv(offsets_nb, sep=',',header=0).squeeze("columns")
                    offsets_x_nb = offsets_nb['offset_x'].fillna(0.1).to_numpy()
                    offsets_y_nb = offsets_nb['offset_y'].fillna(0.1).to_numpy()
                else:
                    offsets_x_nb = default_offsets(sims)
                    offsets_y_nb = default_offsets(sims)

                if offsets_brier.filename != '':
                    offsets_brier = pd.read_csv(offsets_brier, sep=',',header=0).squeeze("columns")
                    offsets_x_brier = offsets_brier['offset_x'].fillna(0.1).to_numpy()
                    offsets_y_brier = offsets_brier['offset_y'].fillna(0.1).to_numpy()
                else:
                    offsets_x_brier = default_offsets(sims)
                    offsets_y_brier = default_offsets(sims)

                if(sims.size != offsets_x_auc.size or sims.size != offsets_x_nb.size or sims.size != offsets_x_brier.size):
                    flash("offsets_x and dataset files must have the same number of elements.", category='danger')
                    return render_template('home.html')

                if(sims.size != offsets_y_auc.size or sims.size != offsets_y_nb.size or sims.size != offsets_y_brier.size):
                    flash("offsets_y and dataset files must have the same number of elements.", category='danger')
                    return render_template('home.html')

                if np.isnan(np.sum(sims)):
                    flash("Similarities must not have any missing values.", category='danger')
                    return render_template('home.html')


                for dataset in datasets:
                    print(dataset)
                    if dataset and not allowed_file(dataset.filename):
                        flash("Dataset files need .csv extension.", category='danger')
                        return render_template('home.html')

                has_extra_columns = False

                for dataset in datasets:
                    filename = secure_filename(dataset.filename)
                    # print(dataset, filename)
                    singleDataset = pd.read_csv(dataset, sep=',').squeeze("columns")
                    y_test = singleDataset['y_true'].to_numpy()
                    y_proba = singleDataset['y_proba'].to_numpy()

                    ths = None
                    if "threshold" in singleDataset.columns:
                        ths = singleDataset['threshold'].to_numpy()

                    rels = None
                    if "relevance" in singleDataset.columns:
                        rels = singleDataset['relevance'].to_numpy()

                    if np.isnan(np.sum(y_test)) or np.isnan(np.sum(y_proba)):
                        flash("y_test and y_proba must have the same number of elements", category='danger')
                        return render_template('home.html')

                    if check_if_0_or_1(y_test):
                        flash("y_test must have only 0 or 1 as elements", category='danger')
                        return render_template('home.html')

                    if not check_if_between_0_and_1(y_proba):
                        flash("y_proba must have only numbers between 0 and 1 as elements", category='danger')
                        return render_template('home.html')

                    if (ths is not None) and (not check_if_between_0_and_1(ths)):
                        flash("thresholds must be missing or have only numbers between 0 and 1 as elements", category='danger')
                        return render_template('home.html')

                    if (rels is not None) and (not check_if_between_0_and_1(rels)):
                        flash("relevances must be missing or have only numbers between 0 and 1 as elements", category='danger')
                        return render_template('home.html')

                    labels = np.append(labels, filename[:-4])
                    texts= np.append(texts, filename[:2])

                    if options.utility_metric == 'wu':
                        if (ths is None):
                            flash("The dataset %s is missing the threshold column: it's required for all datasets to compute the Weighted Utility." % (filename,), category='danger')
                            return render_template('home.html')

                        if np.isnan(np.sum(ths)):
                            flash("The dataset %s has missing values in its threshold column: it's required for all datasets to compute the Weighted Utility." % (filename,), category='danger')
                            return render_template('home.html')

                        if (rels is None):
                            flash("The dataset %s is missing the relevance column: it's required for all datasets to compute the Weighted Utility." % (filename,), category='danger')
                            return render_template('home.html')

                        if np.isnan(np.sum(rels)):
                            flash("The dataset %s has missing values in its relevance column: it's required for all datasets to compute the Weighted Utility." % (filename,), category='danger')
                            return render_template('home.html')

                    if options.utility_metric == 'snb' and (ths is not None or rels is not None):
                        has_extra_columns = True

                    # chiamata compute
                    results = compute(y_test, y_proba, ths, rels, options)

                    aucs= np.append(aucs, results[0])
                    nbs = np.append(nbs, results[1])
                    briers = np.append(briers, results[2])
                    instances = np.append(instances, results[3])
                    samples_auc = np.append(samples_auc, results[4])
                    samples_nb = np.append(samples_nb, results[5])
                    samples_brier = np.append(samples_brier, results[6])
                    var_auc = np.append(var_auc, results[7])
                    var_nb = np.append(var_nb, results[8])
                    var_brier = np.append(var_brier, results[9])


                for x in range(len(labels)):
                    labels[x] = labels[x] + " (" + texts[x] + ")"



                if sims.size != labels.size:
                    print(sims)
                    print(labels)
                    flash("The number of elements in similarities must be equal to the number of dataset files inserted ", category='danger')
                    return render_template('home.html')

                img_step2 = step_two(sims, aucs, nbs, briers, labels, texts, instances, samples_auc, samples_nb, samples_brier,
                                    offsets_x_auc, offsets_y_auc, offsets_x_nb, offsets_y_nb, offsets_x_brier, offsets_y_brier,
                                    var_auc, var_nb, var_brier, options)


            except Exception as e:
                logging.exception(e)
                flash("One or more errors were encountered: please check your data, or contact us if the issue persists.",category="danger")
                return render_template("home.html")

            if (has_extra_columns):
                flash("The threshold and the relevance column have been provided, but they will discarded as not required to compute the Standard Net Benefit.", category='info')

            return render_template('results_plt2.html', img_url=img_step2)

        if test1 is True:
            data = pd.read_csv("./static/testfiles/plt1/inputsplt1.csv", sep=',').squeeze("columns")
            sim = data['similarities'].to_numpy()
            metrics = data['metrics'].to_numpy()
            img_step1 = plot_step_one(sim, metrics, scatter=True)
            return render_template('results_plt1.html', img_url = img_step1)

        if test2 is True:
            aucs = np.array([])
            nbs = np.array([])
            briers = np.array([])
            instances = np.array([])
            samples_auc = np.array([])
            samples_nb = np.array([])
            samples_brier = np.array([])
            var_auc = np.array([])
            var_nb = np.array([])
            var_brier = np.array([])
            labels = ['Bergamo', 'Brazil_0', 'Brazil_1', 'Brazil_2', 'Desio', 'Ethiopia', 'HSR Nov', 'Spain']
            texts = ['Be', 'B0', 'B1', 'B2', 'De', 'Et', 'HS', 'Sp']
            sims = pd.read_csv("./static/testfiles/plt2/sims.csv", sep=',',usecols=['similarities']).squeeze("columns").to_numpy()
            files = ['Bergamo.csv', 'Brazil_0.csv', 'Brazil_1.csv', 'Brazil_2.csv', 'Desio.csv', 'Ethiopia.csv', 'HSR_Nov.csv', 'Spain.csv']

            has_extra_columns = False

            for x in range(len(files)):
                data = pd.read_csv(os.path.join(app.config['TEST_FOLDER'], files[x]), sep=',').squeeze("columns")
                y_test = data['y_true'].to_numpy()
                y_proba = data['y_proba'].to_numpy()

                ths = None
                if "threshold" in data.columns:
                    ths = data['threshold'].to_numpy()

                rels = None
                if "relevance" in data.columns:
                    rels = data['relevance'].to_numpy()

                if options.utility_metric == 'wu':
                    if (ths is None):
                        flash("The dataset %s is missing the threshold column: it's required for all datasets to compute the Weighted Utility." % (files[x],), category='danger')
                        return render_template('home.html')

                    if np.isnan(np.sum(ths)):
                        flash("The dataset %s has missing values in its relevance column: it's required for all datasets to compute the Weighted Utility." % (files[x],), category='danger')
                        return render_template('home.html')

                    if (rels is None):
                        flash("The dataset %s is missing the relevance column: it's required for all datasets to compute the Weighted Utility." % (files[x],), category='danger')
                        return render_template('home.html')

                    if np.isnan(np.sum(rels)):
                        flash("The dataset %s has missing values in its relevance column: it's required for all datasets to compute the Weighted Utility." % (files[x],), category='danger')
                        return render_template('home.html')

                if options.utility_metric == 'snb' and (ths is not None or rels is not None):
                    has_extra_columns = True

                results = compute(y_test, y_proba, ths, rels, options)

                aucs= np.append(aucs, results[0])
                nbs = np.append(nbs, results[1])
                briers = np.append(briers, results[2])
                instances = np.append(instances, results[3])
                samples_auc = np.append(samples_auc, results[4])
                samples_nb = np.append(samples_nb, results[5])
                samples_brier = np.append(samples_brier, results[6])
                var_auc = np.append(var_auc, results[7])
                var_nb = np.append(var_nb, results[8])
                var_brier = np.append(var_brier, results[9])


            offsets_x_auc = default_offsets(sims)
            offsets_y_auc = default_offsets(sims)
            offsets_x_nb = default_offsets(sims)
            offsets_y_nb = default_offsets(sims)
            offsets_x_brier = default_offsets(sims)
            offsets_y_brier = default_offsets(sims)

            for x in range(len(labels)):
                labels[x] = labels[x] + " (" + texts[x] + ")"


            img_step2 = step_two(sims, aucs, nbs, briers, labels, texts, instances, samples_auc, samples_nb, samples_brier,
                                 offsets_x_auc, offsets_y_auc, offsets_x_nb, offsets_y_nb, offsets_x_brier, offsets_y_brier, var_auc, var_nb, var_brier,
                                 options=options)

            if (has_extra_columns):
                flash("The threshold and the relevance column have been provided, but they will discarded as not required to compute the Standard Net Benefit.", category='info')

            return render_template('results_plt2.html', img_url=img_step2)

    else:
        return render_template('home.html')


@app.route('/upload')
def upload():
    return render_template('upload.html')

@app.route('/prd')
def prd():
    return render_template('prd.html')

@app.route('/epd')
def epd():
    return render_template('epd.html')

@app.route('/test/plt1')
def testplt1():
    return choose_form(test1 = True)


@app.route('/test/plt2')
def testplt2():
    return choose_form(test2 = True)

def check_if_between_0_and_1(arr):
    is_between = True
    for elem in arr:
        if elem < 0 or elem > 1:
            return False
    return is_between


def check_if_0_or_1(arr):
    is_0_or_1 = True
    for elem in arr:
        if elem != 0 or elem != 1:
            return False
    return is_0_or_1


def check_if_contains_zero(arr):

    is_zero = False
    for elem in arr:
        if elem == 0:
            return True
    return is_zero


def check_if_positive(arr):
    is_negative = False
    for elem in arr:
        if elem < 0:
            return True
    return is_negative


def default_offsets(arr):
    offset = np.empty(len(arr))
    offset.fill(.01)
    return offset

@app.route("/deploy")
def deploy():
    output = subprocess.check_output('./lib/deploy.sh', stderr=subprocess.STDOUT).replace(b'\n', b'<br />')

    return output

if __name__ == '__main__':
    app.run(debug=True, port=5004)
